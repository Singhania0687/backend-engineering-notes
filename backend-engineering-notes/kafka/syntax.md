# Kafka Generic Syntax
---

# 1ï¸âƒ£ Kafka Producer â€“ General Syntax 

### Producer flow (always the same)

```
1. Create Kafka client
2. Create producer
3. Connect producer
4. Send message(s)
5. Disconnect (optional for long-running apps)
```

### Generic Producer Pseudocode

```
kafka = new Kafka(config)
producer = kafka.createProducer()

producer.connect()

producer.send(
  topic,
  key,
  value,
  headers
)

producer.disconnect()
```

---

## Producer â€“ Key things you must remember

* **topic** â†’ where the event goes
* **key** â†’ decides partition (ordering guarantee)
* **value** â†’ actual event payload (usually JSON)
* **producer is fire-and-forget by default**, unless you wait for ACKs

---

# 2ï¸âƒ£ Kafka Consumer â€“ General Syntax (Mental Model)

### Consumer flow (always the same)

```
1. Create Kafka client
2. Create consumer (with groupId)
3. Connect consumer
4. Subscribe to topic
5. Poll messages continuously
6. Process message
7. Commit offset
```

### Generic Consumer Pseudocode

```
kafka = new Kafka(config)
consumer = kafka.createConsumer(groupId)

consumer.connect()

consumer.subscribe(topic)

while (true):
  records = consumer.poll()
  for record in records:
    process(record)
    commitOffset()
```

---

## Consumer â€“ Key things to remember

* **groupId** â†’ enables load balancing
* **offset** â†’ what you have processed
* **commit offset only after successful processing**
* Kafka **does not push** messages â†’ consumer **polls**

---

# 3ï¸âƒ£ Real Node.js Template (KafkaJS)

## ğŸ”¹ Producer Template (copy & reuse)

```js
const { Kafka } = require("kafkajs");

const kafka = new Kafka({
  clientId: "my-producer",
  brokers: ["localhost:9092"],
});

const producer = kafka.producer();

async function produce() {
  await producer.connect();

  await producer.send({
    topic: "my-topic",
    messages: [
      {
        key: "entity-id",
        value: JSON.stringify({ event: "SOMETHING_HAPPENED" }),
      },
    ],
  });

  // keep connection open in real apps
  await producer.disconnect();
}

produce();
```

---

## ğŸ”¹ Consumer Template (copy & reuse)

```js
const { Kafka } = require("kafkajs");

const kafka = new Kafka({
  clientId: "my-consumer",
  brokers: ["localhost:9092"],
});

const consumer = kafka.consumer({ groupId: "my-group" });

async function consume() {
  await consumer.connect();
  await consumer.subscribe({ topic: "my-topic", fromBeginning: false });

  await consumer.run({
    eachMessage: async ({ message, partition }) => {
      const value = message.value.toString();
      console.log("Consumed:", value);

      // process business logic here
    },
  });
}

consume();
```

---

# 4ï¸âƒ£ Ultra-important interview defaults (MEMORIZE)

### Producer side

* Always set **key** for ordering
* Prefer **JSON** payload
* Think in **events**, not DB rows
* Producer should be **stateless**

---

### Consumer side

* One consumer group = one logical app
* Multiple consumers = parallelism
* Commit offsets **after processing**
* Consumers should be **idempotent**

---

# 5ï¸âƒ£ One-line templates (very powerful)

### Producer one-liner

> Create â†’ connect â†’ send(topic, key, value) â†’ disconnect

### Consumer one-liner

> Create â†’ connect â†’ subscribe â†’ poll â†’ process â†’ commit offset

---

# 6ï¸âƒ£ What interviewers secretly test

If they ask Kafka and you say:

* âŒ â€œKafka pushes messagesâ€
* âŒ â€œKafka stores stateâ€
* âŒ â€œKafka guarantees exactly-once by defaultâ€

Youâ€™re out.

If you say:

* âœ… â€œConsumers poll Kafkaâ€
* âœ… â€œKafka stores immutable eventsâ€
* âœ… â€œExactly-once requires careful config + idempotencyâ€

Youâ€™re in.

---
